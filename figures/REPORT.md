# ЗВІТ з практичного заняття №14: Наука і техніка

**Тема:** Прогнозування енергоспоживання (Track A)
**Студентка:** Зоріна Софія

## 1. Постановка задачі
**Мета:** Побудувати модель прогнозування погодинного енергоспоживання, що перевершує наївний сезонний прогноз.

## 2. Дані та EDA (Розвідувальний аналіз)
Використано погодинний часовий ряд (3 роки). Нижче наведено аналіз структури даних.

**2.1. Загальний огляд споживання:**
На графіку видно загальний тренд та сезонність.
![Overview](figures/eda_overview.png)

**2.2. Розподіл споживання (Гістограма):**
Графік показує частоту різних рівнів навантаження на мережу.
![Distribution](figures/eda_dist.png)

**2.3. Тижневий профіль (останні 7 днів):**
Чітко простежуються добові цикли (день/ніч) та різниця між робочими днями і вихідними.
![Weekly Profile](figures/eda_weekly.png)

## 3. Методи
1. **Baseline:** `Seasonal Naive` (тиждень тому).
2. **XGBoost:** Градієнтний бустинг (500 дерев).
3. **Genetic Programming:** Символьна регресія (`gplearn`).

## 4. Результати
**Порівняння прогнозів (Фрагмент):**
Моделі (особливо XGBoost - синя лінія) дуже точно відтворюють складну структуру ряду порівняно з фактом (чорна лінія).
![Forecast Comparison](figures/forecast_comparison.png)

**Метрики (Test Set):**
| Модель | MAE | RMSE | MAPE (%) |
| :--- | :--- | :--- | :--- |
| Baseline | 656.02 | 818.25 | 3.01% |
| Genetic Programming | 574.84 | 717.98 | 2.66% |
| **XGBoost** | **446.51** | **557.41** | **2.06%** |

## 5. Інтерпретація моделі (XGBoost)
Які фактори найбільше впливають на споживання?
![Feature Importance](figures/feature_importance.png)

Як видно з діаграми, найважливішими ознаками є:
1. `lag_168` (Споживання в цей же час тиждень тому).
2. `lag_1` (Споживання годину тому).
Це підтверджує сильну інерційність та тижневу циклічність енергоспоживання.

## 6. Висновки
1. **XGBoost** показав найкращу точність (MAPE 2.06%), знизивши помилку на ~31% відносно бази.
2. **Генетичне програмування** також впоралося добре (2.66%), знайшовши аналітичну формулу без ручного підбору структури.
3. Обидва методи підходять для використання в реальних умовах прогнозування навантаження.

**1. Що працює (Сильні сторони)**
* **Класичний ML (XGBoost):** Виявився беззаперечним лідером. Він найкраще "вловив" складну сезонність (добову та тижневу) завдяки лаговим ознакам. Зниження помилки на ~30% відносно базової лінії — це відмінний результат для бізнесу.
* **Лагові ознаки:** Створення фічів `lag_168` (тиждень тому) та `lag_24` (доба тому) виявилося критично важливим. Це підтверджує, що енергоспоживання — це інерційний процес із сильною циклічністю.

**2. Де ліміт (Обмеження)**
* **Генетичне програмування:** Хоча `gplearn` знайшов працюючу формулу і перевершив наївний прогноз, він досяг "стелі" точності раніше за бустинг. ГП потребує значно більше часу на навчання, а знайдені формули можуть бути громіздкими (проблема "роздування" коду), якщо не використовувати жорсткі штрафи за довжину.
* **Ізольованість даних:** Моделі спираються лише на історію. Вони не можуть передбачити аномалії, викликані зовнішніми факторами (наприклад, раптовим похолоданням або локдауном), оскільки ці дані не були подані на вхід.

**3. Що б я зробила далі (Подальші кроки)**
* **Додати погоду:** Це головний резерв для покращення. Температура повітря має пряму кореляцію зі споживанням (опалення взимку, кондиціонери влітку). Додавання прогнозу температури як ознаки суттєво підвищить точність.
* **Календар свят:** Енергоспоживання у державні свята різко падає і стає схожим на неділю. Варто додати ознаку `is_holiday`.
* **Гібридний підхід:** Використати Генетичне програмування не як фінальну модель, а як генератор складних ознак (Feature Engineering), які потім подавати на вхід XGBoost.
